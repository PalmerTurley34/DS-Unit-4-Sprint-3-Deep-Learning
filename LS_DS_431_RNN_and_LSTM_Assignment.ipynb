{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PalmerTurley34/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/LS_DS_431_RNN_and_LSTM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC42i_23PqlU",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "rAOoRNFxPqlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "5QOGsDnYPqle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "id": "z40Qe74JPqli",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b5f0228e-5ebc-4053-cb59-b607dad8da22"
      },
      "source": [
        "#Shakespeare Data Parsed by Play\n",
        "df_toc.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ALL’S WELL THAT ENDS WELL</td>\n",
              "      <td>2777</td>\n",
              "      <td>7738</td>\n",
              "      <td>ALL’S WELL THAT ENDS WELL\\r\\n\\r\\n\\r\\n\\r\\nConte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>7739</td>\n",
              "      <td>11840</td>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA\\r\\n\\r\\nDRA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>11841</td>\n",
              "      <td>14631</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\nDRAMATIS PERSONAE.\\r\\n\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>14632</td>\n",
              "      <td>17832</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>17833</td>\n",
              "      <td>27806</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0            ALL’S WELL THAT ENDS WELL  ...  ALL’S WELL THAT ENDS WELL\\r\\n\\r\\n\\r\\n\\r\\nConte...\n",
              "1  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...  THE TRAGEDY OF ANTONY AND CLEOPATRA\\r\\n\\r\\nDRA...\n",
              "2                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\nDRAMATIS PERSONAE.\\r\\n\\r...\n",
              "3                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "4            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx7cEZNijs-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "text = \" \".join(df_toc['text'].values)\n",
        "\n",
        "chars = list(set(text))\n",
        "\n",
        "char_int = {c:i for i, c in enumerate(chars)}\n",
        "int_char = {i:c for i, c in enumerate(chars)}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk9UhviYkSDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 80\n",
        "step = 15\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = []\n",
        "next_char = []\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "  sequences.append(encoded[i : i + maxlen])\n",
        "  next_char.append(encoded[i + maxlen])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tiyz0ctClCc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzG5QC4XlRIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "162f5ede-b502-4c26-d832-f392f30ef082"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(375718, 80, 106)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXrXij6hlqUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwGC1IhSlfiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(106, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5nYKpxzlvDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQtZSYWUl6ut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scz36lr1l7-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "65096c93-6fe2-41c3-91ac-0566933a17b7"
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=256,\n",
        "          epochs=30,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1463/1468 [============================>.] - ETA: 0s - loss: 2.3598\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"re; adieu, good Monsieur\n",
            "  Melancholy. Exit JAQUES ROSALIND. [Aside to CELIA] I\"\n",
            "re; adieu, good Monsieur\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Calds bersereno! I atrestat andil ht it eocLon t and muafrsE\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 2.3592\n",
            "Epoch 2/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 2.1173\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \" no relish of them; but abound\n",
            "In the division of each several crime,\n",
            "Acting i\"\n",
            " no relish of them; but abound\n",
            "In the division of each several crime,\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "   \n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 2.1171\n",
            "Epoch 3/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 2.0195\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"ear;\n",
            "   The one in motley here,\n",
            "     The other found out there.\n",
            "\n",
            "LEAR.\n",
            "Dost\"\n",
            "ear;\n",
            "   The one in motley here,\n",
            "     The other found out there.\n",
            "\n",
            "LEAR.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "    I mighes, bowepr’deng amy suy lovi\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 2.0195\n",
            "Epoch 4/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 1.9487\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"\n",
            "    They shall abound as formerly.\n",
            "  BUCKINGHAM. O, many\n",
            "    Have broke their\"\n",
            "\n",
            "    They shall abound as formerly.\n",
            "  BUCKINGHAM. O, many\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "    My his io eving spore thy ’ortieg and higer, wall thes the p\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.9487\n",
            "Epoch 5/30\n",
            "1467/1468 [============================>.] - ETA: 0s - loss: 1.8963\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"\n",
            "BRUTUS.\n",
            "What, thou speak’st drowsily?\n",
            "Poor knave, I blame thee not, thou art \"\n",
            "\n",
            "BRUTUS.\n",
            "What, thou speak’st drowsily?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Notry hake dath inoth’r yourn S\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.8962\n",
            "Epoch 6/30\n",
            "1467/1468 [============================>.] - ETA: 0s - loss: 1.8544\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"MAS LOVELL, with others. The CARDINAL places himself\n",
            "under the KING'S feet on h\"\n",
            "MAS LOVELL, with others. The CARDINAL places himself\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Regebon thes\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.8544\n",
            "Epoch 7/30\n",
            "1463/1468 [============================>.] - ETA: 0s - loss: 1.8159\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"ding as you are,\n",
            "That you foresee not what impediments\n",
            "Drag back our expeditio\"\n",
            "ding as you are,\n",
            "That you foresee not what impediments\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "s   All pome\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.8159\n",
            "Epoch 8/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 1.7852\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"ighness in this form and with this addition, in\n",
            "French, _Notre très-cher fils H\"\n",
            "ighness in this form and with this addition, in\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The, is a fucle \n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.7851\n",
            "Epoch 9/30\n",
            "1466/1468 [============================>.] - ETA: 0s - loss: 1.7569\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"itiful;\n",
            "And pity to the general wrong of Rome—\n",
            "As fire drives out fire, so pit\"\n",
            "itiful;\n",
            "And pity to the general wrong of Rome—\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  COMOM.         Exen the I \n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.7569\n",
            "Epoch 10/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 1.7398\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"ense,\n",
            "(If she in chains of magic were not bound)\n",
            "Whether a maid so tender, fai\"\n",
            "ense,\n",
            "(If she in chains of magic were not bound)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CO\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.7398\n",
            "Epoch 11/30\n",
            "1464/1468 [============================>.] - ETA: 0s - loss: 1.7153\n",
            "----- Generating text after Epoch: 10\n",
            "----- Generating with seed: \"ke could have restord\n",
            "My lost strength to me, I was growne so low,\n",
            "And Crest-f\"\n",
            "ke could have restord\n",
            "My lost strength to me, I was growne so low,\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "    Yeves temay peebdou\n",
            "1468/1468 [==============================] - 29s 20ms/step - loss: 1.7154\n",
            "Epoch 12/30\n",
            "1463/1468 [============================>.] - ETA: 0s - loss: 1.6982\n",
            "----- Generating text after Epoch: 11\n",
            "----- Generating with seed: \"\n",
            "\n",
            "GENTLEWOMAN.\n",
            "Pray God it be, sir.\n",
            "\n",
            "DOCTOR.\n",
            "This disease is beyond my prac\"\n",
            "\n",
            "\n",
            "GENTLEWOMAN.\n",
            "Pray God it be, sir.\n",
            "\n",
            "DOCTOR.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "    Whene, the in ase much apus to you\n",
            "1468/1468 [==============================] - 29s 19ms/step - loss: 1.6980\n",
            "Epoch 13/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 1.6812\n",
            "----- Generating text after Epoch: 12\n",
            "----- Generating with seed: \" money for the same.\n",
            "Pleaseth you walk with me down to his house,\n",
            "I will disch\"\n",
            " money for the same.\n",
            "Pleaseth you walk with me down to his house,\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "But here\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.6812\n",
            "Epoch 14/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 1.6658\n",
            "----- Generating text after Epoch: 13\n",
            "----- Generating with seed: \"do leave me to mine own protection.\n",
            "\n",
            "GRATIANO.\n",
            "Well, do you so. Let not me ta\"\n",
            "do leave me to mine own protection.\n",
            "\n",
            "GRATIANO.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Why hours lase werl\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.6656\n",
            "Epoch 15/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 1.6539\n",
            "----- Generating text after Epoch: 14\n",
            "----- Generating with seed: \"!\n",
            "\n",
            "IAGO.\n",
            "Gentlemen all, I do suspect this trash\n",
            "To be a party in this injury\"\n",
            "!\n",
            "\n",
            "IAGO.\n",
            "Gentlemen all, I do suspect this trash\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "This prothemphte: he is no, gies a suie and \n",
            "1468/1468 [==============================] - 29s 19ms/step - loss: 1.6540\n",
            "Epoch 16/30\n",
            "1463/1468 [============================>.] - ETA: 0s - loss: 1.6389\n",
            "----- Generating text after Epoch: 15\n",
            "----- Generating with seed: \"eating and hanging are\n",
            "terrors to me. For the life to come, I sleep out the tho\"\n",
            "eating and hanging are\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "So\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.6389\n",
            "Epoch 17/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 1.6277\n",
            "----- Generating text after Epoch: 16\n",
            "----- Generating with seed: \" Another room in Cymbeline’s palace.\n",
            "Scene III. Wales. A mountainous country wi\"\n",
            " Another room in Cymbeline’s palace.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "That thang you sh\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.6276\n",
            "Epoch 18/30\n",
            "1464/1468 [============================>.] - ETA: 0s - loss: 1.6182\n",
            "----- Generating text after Epoch: 17\n",
            "----- Generating with seed: \"njunctions everyone doth swear\n",
            "That comes to hazard for my worthless self.\n",
            "\n",
            "A\"\n",
            "njunctions everyone doth swear\n",
            "That comes to hazard for my worthless self.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  KING HENTE. An the time\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.6182\n",
            "Epoch 19/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 1.6058\n",
            "----- Generating text after Epoch: 18\n",
            "----- Generating with seed: \"ng; they have skift\n",
            "Torrents whose roring tyranny and power\n",
            "I'th least of thes\"\n",
            "ng; they have skift\n",
            "Torrents whose roring tyranny and power\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "    To grived-bay. I'ss're is me is chance and my sen\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.6058\n",
            "Epoch 20/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 1.5963\n",
            "----- Generating text after Epoch: 19\n",
            "----- Generating with seed: \" stain'd excuse.\n",
            "\n",
            "Besides, the life and feeling of her passion\n",
            "She hoards, to\"\n",
            " stain'd excuse.\n",
            "\n",
            "Besides, the life and feeling of her passion\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Go \n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.5962\n",
            "Epoch 21/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 1.5880\n",
            "----- Generating text after Epoch: 20\n",
            "----- Generating with seed: \"th a ling’ring dram, that should not work\n",
            "Maliciously like poison. But I cannot\"\n",
            "th a ling’ring dram, that should not work\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Thy efeething and rein, and swiet\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.5880\n",
            "Epoch 22/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 1.5786\n",
            "----- Generating text after Epoch: 21\n",
            "----- Generating with seed: \"ost thee.\n",
            "\n",
            "ANTONIO.\n",
            "Sebastian are you?\n",
            "\n",
            "SEBASTIAN.\n",
            "Fear’st thou that, Anto\"\n",
            "ost thee.\n",
            "\n",
            "ANTONIO.\n",
            "Sebastian are you?\n",
            "\n",
            "SEBASTIAN.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "But they manly, to any he dient compic\n",
            "1468/1468 [==============================] - 29s 20ms/step - loss: 1.5784\n",
            "Epoch 23/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 1.5750\n",
            "----- Generating text after Epoch: 22\n",
            "----- Generating with seed: \"sh’d. Yet look how far\n",
            "The substance of my praise doth wrong this shadow\n",
            "In un\"\n",
            "sh’d. Yet look how far\n",
            "The substance of my praise doth wrong this shadow\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "“The fantors, whree as the word molt the weid'\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.5751\n",
            "Epoch 24/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 1.5620\n",
            "----- Generating text after Epoch: 23\n",
            "----- Generating with seed: \" do.\n",
            "\n",
            "ORLEANS.\n",
            "What a wretched and peevish fellow is this King of England, to\"\n",
            " do.\n",
            "\n",
            "ORLEANS.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Sir t\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.5621\n",
            "Epoch 25/30\n",
            "1467/1468 [============================>.] - ETA: 0s - loss: 1.5551\n",
            "----- Generating text after Epoch: 24\n",
            "----- Generating with seed: \"\n",
            "HIPPOLITA.\n",
            "Next, heare my prayers.\n",
            "\n",
            "EMILIA.\n",
            "Last, let me intreate, Sir.\n",
            "\"\n",
            "\n",
            "HIPPOLITA.\n",
            "Next, heare my prayers.\n",
            "\n",
            "EMILIA.\n",
            "Last, let me intreate, Sir.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Beloss vialian stabstess, \n",
            "1468/1468 [==============================] - 29s 19ms/step - loss: 1.5551\n",
            "Epoch 26/30\n",
            "1467/1468 [============================>.] - ETA: 0s - loss: 1.5486\n",
            "----- Generating text after Epoch: 25\n",
            "----- Generating with seed: \"d you from England\n",
            "Are here arriv’d, give order that these bodies\n",
            "High on a st\"\n",
            "d you from England\n",
            "Are here arriv’d, give order that these bodies\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "    well that, your gie. ‘Shorm, sirs to who as\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.5485\n",
            "Epoch 27/30\n",
            "1465/1468 [============================>.] - ETA: 0s - loss: 1.5420\n",
            "----- Generating text after Epoch: 26\n",
            "----- Generating with seed: \"odest as morning when she coldly eyes\n",
            "The youthful Phoebus.\n",
            "Which is that god \"\n",
            "odest as morning when she coldly eyes\n",
            "The youthful Phoebus.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "It is\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.5419\n",
            "Epoch 28/30\n",
            "1467/1468 [============================>.] - ETA: 0s - loss: 1.5350\n",
            "----- Generating text after Epoch: 27\n",
            "----- Generating with seed: \"\n",
            "\n",
            "MARIA.\n",
            "Ass, I doubt not.\n",
            "\n",
            "SIR ANDREW.\n",
            "O ’twill be admirable!\n",
            "\n",
            "MARIA.\n",
            "\"\n",
            "\n",
            "\n",
            "MARIA.\n",
            "Ass, I doubt not.\n",
            "\n",
            "SIR ANDREW.\n",
            "O ’twill be admirable!\n",
            "\n",
            "MARIA.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Vear, his best up that h\n",
            "1468/1468 [==============================] - 29s 19ms/step - loss: 1.5351\n",
            "Epoch 29/30\n",
            "1467/1468 [============================>.] - ETA: 0s - loss: 1.5296\n",
            "----- Generating text after Epoch: 28\n",
            "----- Generating with seed: \"e,\n",
            "  And Lust, the thief, far poorer than before.\n",
            "\n",
            "Look, as the full-fed houn\"\n",
            "e,\n",
            "  And Lust, the thief, far poorer than before.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Ardisicgity, aba\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.5295\n",
            "Epoch 30/30\n",
            "1463/1468 [============================>.] - ETA: 0s - loss: 1.5234\n",
            "----- Generating text after Epoch: 29\n",
            "----- Generating with seed: \"r\n",
            "      Benedick! Friar!\n",
            "\n",
            "\n",
            "      LEONATO.\n",
            "      O Fate! take not away thy h\"\n",
            "r\n",
            "      Benedick! Friar!\n",
            "\n",
            "\n",
            "      LEONATO.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "    No the bott, with his wear n\n",
            "1468/1468 [==============================] - 28s 19ms/step - loss: 1.5233\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff75e060550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}